


  <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Podstawowe procesy stochastyczne &mdash; Dynamika stochastyczna</title>
    
    <link rel="stylesheet" href="../_static/upgow.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Noticia+Text|Open+Sans|Droid+Sans+Mono&subset=latin,latin-ext" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     'I',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/translations.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/jquery.cookie.js"></script>
    <script type="text/javascript" src="../_static/cloud.js"></script>
	<script src="http://sagecell.icse.us.edu.pl:6363/static/jquery.min.js"></script>
	<script src="http://sagecell.icse.us.edu.pl:6363/static/embedded_sagecell.js"></script>
	
	<!-- <script src="http://sagecell.sagemath.org/static/jquery.min.js"></script> -->
        <!--     <script src="http://sagecell.sagemath.org/static/embedded_sagecell.js"></script> -->

	<script>sagecell.makeSagecell({inputLocation: ".sage"});</script>

	<style type="text/css">
		.sagecell .CodeMirror-scroll {
			overflow-y: hidden;
			overflow-x: auto;
		}
		.sagecell .CodeMirror {
			height: auto;
		}
	</style>

    
    <link rel="top" title="Dynamika stochastyczna" href="../index.html" />
    <link rel="next" title="Rachunki w całkach Ito - Stratonowicza" href="chIII030.html" />
    <link rel="prev" title="Równania stochastyczne i ich interpretacja" href="chIII011.html" />
 
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1">
  </head>
  <body>
  <div class="relbar-top">
    
    <div class="related">
      <h3>Nawigacja</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="Indeks ogólny"
             accesskey="I">indeks</a></li>
        <li class="right" >
          <a href="chIII030.html" title="Rachunki w całkach Ito - Stratonowicza"
             accesskey="N">dalej</a> &nbsp; &nbsp;</li>
        <li class="right" >
          <a href="chIII011.html" title="Równania stochastyczne i ich interpretacja"
             accesskey="P">wstecz</a> &nbsp; &nbsp;</li>
  <li><a href="../index.html">Dynamika stochastyczna</a> &raquo;</li>
   
      </ul>
    </div>
  </div>
  
  <div class="content">  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="podstawowe-procesy-stochastyczne">
<h1>Podstawowe procesy stochastyczne<a class="headerlink" href="#podstawowe-procesy-stochastyczne" title="Stały odnośnik do tego nagłówka">¶</a></h1>
<p>W wielkim skrócie przedstawimy 3 podstawowe rodzaje procesów stochastycznych. Ich transformacje służą do definicji szumów, fluktuacji i zaburzeń losowych. Czytelnik znajdzie szczegóły i więcej informacji w podręczniku &#8220;Procesy i zjawiska losowe&#8221;.  W sensie matematycznym, większość podstawowych procesów losowych wywodzi się z prób Bernoulliego i uogólnionych prób Bernoulliego. Można by powiedzieć, że dwie próby Bernoulliego odgrywają kluczową role:</p>
<ol class="arabic simple">
<li>wielokrotny rzut monetą</li>
<li>losowe wybieranie punktów z pewnego przedziału liczbowego</li>
</ol>
<p>Pierwszy rodzaj prób Bernoulliego w granicy prowadzi do procesu Wienera, drugi - w granicy prowadzi do procesu Poissona. Obie te granice są różne i odpowiadają dwóm klasom procesów stochastycznych. Oba te procesy są szczególnym przypadkiem procesu, który nazywa się procesem Levy&#8217;ego. Byłoby trudno wyprowadzić ogólny proces Levy&#8217;ego z prób Bernoulliego.</p>
<p>Jako model zaburzeń losowych, w ogólności możemy wybierać dowolny proces stochastyczny. Czasami nakładane są różne ograniczenia jak np. aby był to proces stacjonarny, albo proces o skończonej wartości średniej, albo proces o zerowej wartości średniej, albo proces Markowa, albo proces nieskorelowany, itd. Często zakłada się, że zaburzenie losowe jest o zerowej wartości średniej:</p>
<div class="math" id="equation-eqn1">
<span class="eqno">(1)</span>\[\langle \eta(t)\rangle = 0\]</div>
<p>Jeżeli jest to proces stacjonarny to jego funkcja korelacyjna</p>
<div class="math" id="equation-eqn2">
<span class="eqno">(2)</span>\[\langle \eta(t) \eta(s)\rangle = C(t-s)\]</div>
<p>zależy tylko od różnicy czasów <span class="math">\(t\)</span> oraz <span class="math">\(s\)</span>. Jeżeli jest to proces nieskorelowany to jego funkcja korelacyjna</p>
<div class="math" id="equation-eqn3">
<span class="eqno">(3)</span>\[C(t-s) = 2D_0 \delta(t-s)\]</div>
<p>modelowana jest przez deltę Diraca <span class="math">\(\delta(t)\)</span>, gdzie wielkość <span class="math">\(D_0\)</span> nazywa się natężeniem lub intensywnością procesy stochastycznego. Dlaczego jest to proces nieskorelowany? Ponieważ dla dwóch różnych chwil czasu <span class="math">\(t \ne s\)</span> delta Diraca <span class="math">\(\delta(t-s) = 0\)</span>. Oczywiście są inne, bardziej ogólne definicje procesu nieskorelowanego, ale dla naszych potrzeb powyższa definicja wykorzystująca deltę Diraca jest wystarczająca.</p>
<p>Z kolei przez szum rozumiemy zwykle stacjonarny proces stochastyczny. Dla procesu stacjonarnego możemy wprowadzić pojęcie widma mocy szumu (gęstość spektralna szumu) <span class="math">\(S(\omega)\)</span> jako transformata Fouriera jego funkcji korelacyjnej, tzn.</p>
<div class="math" id="equation-eqn4">
<span class="eqno">(4)</span>\[S(\omega) = \int_{-\infty}^{ \; \infty} \mbox{e}^{i\omega \tau} C(\tau) d\tau\]</div>
<p>gdzie wprowadziliśmy oznaczenie <span class="math">\(\tau = t- s\)</span>.</p>
<p>Gdy funkcja korelacyjna jest deltą Diraca to widmo mocy</p>
<div class="math" id="equation-eqn5">
<span class="eqno">(5)</span>\[S(\omega) = \int_{-\infty}^{ \; \infty} \mbox{e}^{i\omega \tau} 2D_0 \delta(\tau) d\tau = 2 D_0\]</div>
<p>nie zależy od częstości <span class="math">\(\omega\)</span>.W optyce widmo mocy niezależne od częstości jest charakterystyczne dla światła białego (jest to mieszanka wszystkich barw, czyli wszystkich częstości). Dlatego taki szum nazywa się białym szumem. Jeżeli szum jest skorelowany, to niektórzy autorzy nazywają taki szum szumem kolorowym, aby go odróżnić od szumu białego. Często taki kolorowy szum jest scharakteryzowany przez czas korelacji i jego widmo mocy zależy od częstości <span class="math">\(\omega\)</span>. Należy jednak powiedzieć, że szum skorelowany i szum kolorowy są synonimami tego samego pojęcia.</p>
<p>W Naturze biały szum nie występuje. Jest on kolejną idealizacją opisu rzeczywistych procesów. Jest to dobra idealizacja gdy czas korelacji szumu jest najmniejszym charakterystycznym czasem w badanym układzie. Poniżej prezentujemy kilka najbardziej popularnych modeli procesów stochastycznych oraz białego i kolorowego szumu losowego.</p>
<div class="section" id="proces-wienera">
<h2>Proces Wienera<a class="headerlink" href="#proces-wienera" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>Dyskretne błądzenie przypadkowe jest jedną z realizacji wielokrotnego rzutu monetą: w losowy sposób cząstka błądząca wykonuje krok o długości <span class="math">\(L\)</span> w prawo z prawdopodobieństwem <span class="math">\(p\)</span> lub krok o długości <span class="math">\(L\)</span> w lewo z prawdopodobieństwem <span class="math">\(q\)</span>. przy czym <span class="math">\(p+q=1\)</span>. Cząstka wykonuje kroki w odstępach czasu <span class="math">\(T\)</span>.</p>
<div class="figure align-center">
<img alt="figchIII0200" src="../_images/randomwalk.png" style="width: 80%;" />
<p class="caption">Błądzenie przypadkowe.</p>
</div>
<p>Pytamy, jakie jest prawdopodobieństwo tego, że po wykonaniu <span class="math">\(n\)</span> kroków, cząstka będzie w położeniu <span class="math">\(r = \{-n, -n+1, -n+2,..., 0, 1, 2,..., n-1, n\}\)</span>; dokładniej mówiąc, po czasie <span class="math">\(t=nT\)</span> będzie w położeniu <span class="math">\(x=rL\)</span>. W granicy</p>
<div class="math" id="equation-eqn6">
<span class="eqno">(6)</span>\[L\to 0, \quad, T\to 0, \quad \mbox{w taki sposób, aby} \quad \frac{L^2}{T} = const. = 2D\]</div>
<p>gdzie stałą <span class="math">\(D\)</span> nazywa się współczynnikiem dyfuzji lub natężeniem (intensywnością) procesu stochastycznego.</p>
<div class="figure align-center">
<img alt="figchIII0200a" src="../_images/brownian_walk.png" style="width: 80%;" />
<p class="caption">Dwie realizacje błądzenia przypadkowego.</p>
</div>
<p>Innymi słowy, cząstka wykonuje coraz to mniejsze kroki z coraz to większą częstotliwością. W granicy otrzymujemy ciągły proces błądzenia przypadkowego. Jeżeli prawdopodobieństwa <span class="math">\(p=q=1/2\)</span>, błądzenie jest symetryczne i nazywa się procesem Wienera. Ma on następujące własności:</p>
<ol class="arabic simple">
<li>Proces stochastyczny Wienera <span class="math">\(W(t)\)</span> jest procesem rzeczywistym.</li>
<li><span class="math">\(W(0)=0\)</span> (proces startuje z zera, ale to nie jest istotne; jest to wygodne).</li>
<li>Proces <span class="math">\(W(t)\)</span> ma stacjonarne i niezależne przyrosty na nieprzekrywających się przedziałach.</li>
</ol>
<blockquote>
<div><p>Oznacza to, że 2 przyrosty procesu Wienera <span class="math">\(W(t_4) - W(t_3)\)</span> oraz <span class="math">\(W(t_2) - W(t_1)\)</span> są niezależne dla dowolnych chwil czasu takich że <span class="math">\(t_1 \le t_2 \le t_3 \le t_4\)</span>. Innymi słowy wartość średnia</p>
<div class="math" id="equation-eqn7">
<span class="eqno">(7)</span>\[\langle [W(t_4) - W(t_3)] [W(t_2) - W(t_1)] \rangle = \langle W(t_4) - W(t_3)\rangle\langle W(t_2) - W(t_1)\rangle\]</div>
</div></blockquote>
<ol class="arabic simple" start="4">
<li><span class="math">\(W(t)\)</span> jest procesem Gaussa o zerowej wartości średniej</li>
</ol>
<blockquote>
<div><div class="math" id="equation-eqn8">
<span class="eqno">(8)</span>\[\langle W(t_2) - W(t_1) \rangle = 0\]</div>
<p>i wariancji przyrostów</p>
<div class="math" id="equation-eqn9">
<span class="eqno">(9)</span>\[\begin{split}\langle [W(t_2) - W(t_1)]^2 \rangle = 2D(t_2 - t_1), \; \; \; \; t_2 &gt; t_1\end{split}\]</div>
</div></blockquote>
<p>Korzystając z własności 3 można obliczyć funkcję korelacyjną procesy Wienera:</p>
<div class="math" id="equation-eqn10">
<span class="eqno">(10)</span>\[\langle W(t_2) W(t_1) \rangle = 2D \mbox{min} (t_2, t_1) = 2D [ t_1 \theta(t_2 - t_1) + t_2 \theta(t_1 -t_2)]\]</div>
<p>gdzie funkcja <span class="math">\(\mbox{min}(t,s)\)</span> oznacza mniejszą z 2 wartości <span class="math">\(t\)</span> i <span class="math">\(s\)</span>. Funkcję te można wyrazić w matematycznym zapisie korzystając z funkcji skokowej Heaviside&#8217;a <span class="math">\(\theta(x)\)</span>. Przyrost <span class="math">\(W(t_2) - W(t_1)\)</span> jest zmienna losową gaussowską o zerowej wartości średniej i wariancji <span class="math">\(\sigma^2 = 2D(t_2 - t_1)\)</span>. Więc jego rozkład prawdopodobieństwa ma postać</p>
<div class="math" id="equation-eqn11">
<span class="eqno">(11)</span>\[f_{W(t_2) - W(t_1)}(x) = \frac{1}{\sqrt{4\pi D (t_2 - t_1)} }\; \exp \left[ - \frac{x^2}{4D(t_2 - t_1)}\right]\]</div>
<p>Przyjmując <span class="math">\(t_1=0\)</span> oraz <span class="math">\(t_2=t\)</span> otrzymamy gęstość prawdopodobieństwa w postaci</p>
<div class="math" id="equation-eqn12">
<span class="eqno">(12)</span>\[f_{W(t)}(x) = f(x, t) = \frac{1}{\sqrt{4\pi D t} }\; \exp \left[ - \frac{x^2}{4Dt}\right]\;\]</div>
<p>Funkcja charakterystyczna <span class="math">\(C(\omega, t)\)</span> procesu Wienera ma postać:</p>
<div class="math" id="equation-eqn13">
<span class="eqno">(13)</span>\[C(\omega, t) = \langle \mbox{e}^{i\omega W(t)} \rangle = \int_{-\infty}^{\; \infty} \mbox{e}^{i\omega x} f(x, t)\; dx  = \mbox{e}^{-Dt \omega^2}\]</div>
<p>Prawdopodobieństwo tego, że w chwili <span class="math">\(t\)</span> cząstka jest w przedziale <span class="math">\([a, b]\)</span> dane jest przez wzór</p>
<div class="math" id="equation-eqn14">
<span class="eqno">(14)</span>\[Pr\{W(t) \in (a, b)\} = \int_a^{\; b} f(x, t) \; dx = \frac{1}{\sqrt{4\pi D t} }\; \int_a^{\; b} \exp \left[ - \frac{x^2}{4Dt}\right] \; dx\]</div>
<p>Czytelnik zauważy, że niekonsekwentnie piszemy czasami przedział domknięty <span class="math">\([a, b]\)</span>, a czasami przedział otwarty <span class="math">\((a, b)\)</span>. W tym przypadku jest to bez różnicy ponieważ</p>
<div class="math" id="equation-eqn15">
<span class="eqno">(15)</span>\[Pr\{W(t) \in (a, b)\} = Pr\{W(t) \in [a, b]\} = Pr\{W(t) \in [a, b)\} = Pr\{W(t) \in (a, b])\}\]</div>
<p>Proszę zwrócić uwagę na 4 możliwe przedziały w tych wyrażeniach.
Proces Wienera jest granicznym przypadkiem błądzenia losowego: kroki są coraz mniejsze i coraz częstsze. Rozpatrzmy realizacje błądzenia przypadkowego w określonym przedziale czasu <span class="math">\([0, t]\)</span>. W przedziale tym wybrana realizacja posiada określoną ilość skoków w których funkcja ta jest nieróżniczkowalna. Przy skalowaniu skoki są coraz mniejsze, ale jest ich znacznie więcej. Więc w przedziale czasu <span class="math">\([0, t]\)</span> realizacja posiada znaczniej więcej punktów, w których jest nieróżniczkowalna. W granicy, wielkość skoków dąży do zera, ale ich ilość dąży do nieskończoności. Oznacza to, że realizacja staje się funkcją ciągłą (wysokość skoków dąży do zera), ale jednocześnie nigdzie nie jest różniczkowalna (liczba skoków dąży do nieskończoności). Jest to przykład wyjątkowo dziwnej funkcji. Takiej funkcji nie możemy narysować, ale to co opisano powyżej powinno wyrobić w nas intuicję o własnościach realizacji procesu Wienera. Matematycy (jak zwykle) dowodzą to ściśle, a fizycy to czują i wiedzą dlaczego tak jest. Należy także pamiętać, że taki graniczny proces nie istnieje w rzeczywistości. Rzeczywiste procesy błądzenia przypadkowego mają różne długości (ale nie nieskończenie małe) oraz odbywają się z niezerową częstotliwością (<span class="math">\(T\)</span> nie jest nieskończenie małe). Jednak gdy <span class="math">\(T\)</span> jest najmniejszą skalą czasową w badanym układzie, a każde inne czasy charakterystyczne są znacznie większe, to przybliżenie otrzymane po operacji dokonania granic jest rozsądne. To jest przykład kolejnej idealizacji, jaką stosują fizycy do opisu rzeczywistości.</p>
<p>Proces Wienera jest procesem gaussowskim (normalnym), co jest konsekwencją centralnego twierdzenia granicznego: proces jest wynikiem bardzo wielu niezależnych losowych zdarzeń, dlatego niezależnie od rozkładu prawdopodobieństwa każdego z tych zdarzeń, jego rozkład będzie zbliżony do normalnego.</p>
<p>Poniżej pokazujemy jedną z możliwych&nbsp; realizacji (trajektorii) procesu Wienera. Czytelnik może sam wygenerować inne realizacje, zmieniając parametry pojawiające się w programie.</p>
<div class='sage'><script type='text/x-sage'># parametry symulacji
h = 0.01 #krok
N = 5000 #ilosc krokow
# parametry SDE
x0 = 0 #wartosc poczatkowa
D = 0.01 #wspolczynnik dyfuzji
x = [x0]
for i in xrange(1,N):
  n01 = normalvariate(0,1)
  x.append(x[i-1] + sqrt(2*h*D) * n01)
list_plot(x, plotjoined=True, axes_labels=[r'$t$',r'$x(t)$'], figsize=[8,3], frame=1, axes=0)</script></div></div>
<div class="section" id="proces-poissona">
<h2>Proces Poissona<a class="headerlink" href="#proces-poissona" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>Rozważamy przedział liczbowy <span class="math">\([0, T]\)</span>. Z przedziału tego wybieramy losowo jeden punkt, jedną liczbę. Ponieważ wszystkie liczby są &#8220;równo rozłożone&#8221;, więc prawdopodobieństwo tego, że punkt ten jest w przedziale <span class="math">\((t_1, t_2)\subset [0, T]\)</span> wynosi</p>
<div class="math" id="equation-eqn16">
<span class="eqno">(16)</span>\[P(A)= p = \frac{t_2 -t_1}{T}\]</div>
<p>Jeżeli wylosowany punkt jest w tym przedziale, uważam to za sukces. Wybieramy teraz losowo n punktów z przedziału <span class="math">\([0, T]\)</span>. Prawdopodobieństwo tego, że k z tych wszystkich n-punktów będzie w przedziale <span class="math">\((t_1, t_2)\subset [0, T]\)</span> jest określone przez rozkład dwumianowy <span class="math">\(p_n(k)\)</span>. Jeżeli przedział <span class="math">\([0, T]\)</span> będzie przedziałem czasowym, to w przedziale tym mamy <span class="math">\(n\)</span> losowych chwil czasu oraz <span class="math">\(k \le n\)</span> losowych chwil czasu w przedziale <span class="math">\((t_1, t_2)\subset [0, T]\)</span>. Teraz wykonujemy przejście graniczne:</p>
<div class="math" id="equation-eqn17">
<span class="eqno">(17)</span>\[n \to \infty, \;\;\; p \to 0 \;\;\;\; \mbox{ale} \;\;n\cdot p = \frac{n(t_2 - t_1)}{T} = \lambda\]</div>
<p>co da się osiągnąć gdy założymy że <span class="math">\(T \to \infty\)</span> przy czym</p>
<div class="math" id="equation-eqn18">
<span class="eqno">(18)</span>\[\mu = \frac{n}{T}\]</div>
<p>jest stałą wielkością i oznacza ilość losowych punktów w jednostkowym przedziale, czyli gęstość losowo wybranych punktów na osi czasu.
Przy takim skalowaniu otrzymamy wyrażenie na parametr</p>
<div class="math" id="equation-eqn19">
<span class="eqno">(19)</span>\[\lambda = \mu (t_2 -t_1)\]</div>
<p>Przypiszmy teraz każdej losowej chwili czasu akt narodzin dziecka. Prawdopodobieństwo tego że
w przedziale <span class="math">\((t_1, t_2)\)</span> jest k-punktów odpowiada prawdopodobieństwu tego że w przedziale
czasu <span class="math">\((t_1, t_2)\)</span> urodziło się k dzieci. W ten sposób otrzymujemy losowy proces urodzin.
Elementem losowym jest czas narodzin. Wynikiem jest liczba dzieci <span class="math">\(N(t)\)</span> w pewnej chwili
czasu <span class="math">\(t\)</span>. Rozkład prawdopodobieństwa jest dany przez rozkład Poissona, opisujący
prawdopodobieństwo tego, że <span class="math">\(k\)</span> dzieci urodzi się w przedziale <span class="math">\((t_1,t_2)\)</span>:</p>
<div class="math" id="equation-eqn20">
<span class="eqno">(20)</span>\[ Pr\{k,(t_1, t_2)\} = Pr\{N(t_2) - N(t_1) =k\} = e^{-\mu (t_2 - t_1)} \; \frac{[\mu (t_2 - t_1)]^k}{k!}\]</div>
<p>Przyjmijmy teraz, że <span class="math">\(t_1 = 0\)</span> i <span class="math">\(t_2 =t\)</span>. Wówczas <span class="math">\(t_2 - t_1 =t-0=t\)</span> oraz</p>
<div class="math" id="equation-eqn21">
<span class="eqno">(21)</span>\[ p_k(t) = Pr\{N(t) = k\} = Pr\{k,(0, t)\} = \mbox{e}^{-\mu t} \; \frac{(\mu t)^k}{k!}\]</div>
<p>jest prawdopodobieństwem tego, że w przedziale czasu <span class="math">\((0, t)\)</span> urodziło się k dzieci. Jeżeli liczbę urodzonych dzieci oznaczymy przez <span class="math">\(N(t)\)</span> to otrzymamy proces stochastyczny nazywany procesem urodzin. Założymy, że <span class="math">\(N(0) = 0\)</span>. Oczywiście nie jest to bezwzględny wymóg, ale konwencja. Równie dobrze mógłbym badać dowolny inny stan początkowy <span class="math">\(N(0)\)</span>. Proces urodzin tak jak każda zmienna losowa o rozkładzie Poissona przyjmuje wartości całkowite nieujemne:</p>
<div class="math" id="equation-eqn22">
<span class="eqno">(22)</span>\[N(t) = \{0, 1, 2, \dots\}\]</div>
<p>Jeżeli <span class="math">\(N(t) = k\)</span> to mówimy, że układ jest w stanie <span class="math">\(k\)</span>.
Takie sformułowanie jest często stosowane przez fizyków, zwłaszcza w
kontekście fizyki kwantowej, gdzie stanami mogą być poziomy energetyczne
układów kwantowych. Proces urodzin odpowiadałby przejściu z jednego
poziomu energetycznego do najbliższego wyższego poziomu energetycznego.
Przejście do stanu o niższej energii nie jest opisane procesem urodzin,
ale procesem urodzin i śmierci.</p>
<p>Można udowodnić, że przyrosty procesu urodzin <span class="math">\(N(t_2) - N(t_1)\)</span> oraz <span class="math">\(N(t_4) - N(t_3)\)</span> na <em>nieprzekrywających się przedziałach</em> <span class="math">\((t_1, t_2)\)</span> oraz <span class="math">\((t_3, t_4)\)</span> są zmiennymi losowymi niezależnymi. Jest to bardzo ważna własność procesu urodzin o poissonowskiej statystyce losowych chwil urodzin <span class="math">\(t_i\)</span>. Przyrost procesu urodzin <span class="math">\(N(t_2) - N(t_1)\)</span> jest stacjonarny, to znaczy, że prawdopodobieństwu tego że w przedziale czasu <span class="math">\((t_1, t_2)\)</span> urodziło się k dzieci zależy od różnicy
czasów <span class="math">\(t_2-t_1\)</span>, a nie zależy od tego gdzie te chwile czasu <span class="math">\(t_1\)</span> i <span class="math">\(t_2\)</span> są na osi czasu. Jeżeli tak jest, to w ogólnym przypadku mówimy, że <em>proces stochastyczny ma przyrosty stacjonarne</em>. Uwaga: sam proces nie jest stacjonarny ponieważ rozkład prawdopodobieństwa zależy od czasu ale proces ma stacjonarne przyrosty!
Realizacje procesu są <em>nieciągłymi</em> i niemalejącymi funkcjami czasu i są to funkcje schodkowe o skoku 1, przy czym skok następuje w losowych chwilach czasu <span class="math">\(t_i\)</span> (zakładamy, że tylko jeden osobnik rodzi się w danym momencie czasu <span class="math">\(t_i\)</span> i w rzeczywistości jest to prawda abstrahując od kwestii spornych przy cesarskim cięciu w przypadku wielodzietnych ciąży). Funkcje schodkowe można zapisać przy pomocy funkcji theta Heaviside&#8217;a, więc proces urodzin <span class="math">\(N(t)\)</span> można przedstawić w eleganckiej matematycznej postaci:</p>
<div class="math" id="equation-eqn23">
<span class="eqno">(23)</span>\[N(t) = \sum_{i=1}^{\infty} \theta(t-t_i)\]</div>
<p>Aby otrzymać jedną realizację procesu urodzin w przedziale czasu <span class="math">\([0, T]\)</span>, należy losowo wybrać w tym przedziale punkty <span class="math">\(t_i\)</span> które są momentami urodzenia. Mówimy, że punkty te mają statystykę Poissona, mając na myśli ich jednorodne (ale losowe) rozłożenie na osi czasu. Mimo że realizacje są funkcjami nieciągłymi (punktami nieciągłości są skoki), proces ten <em>jest procesem ciągłym</em> w sensie średnio-kwadratowym! Co to oznacza? Poglądowo oznacza to tyle, że jeżeli wybiorę jakiś punkt <span class="math">\(t\)</span> na osi czasu, to realizacje będą ciągłe w tym punkcie. Inaczej mówiąc, prawdopodobieństwo tego, że punkt <span class="math">\(t\)</span> &#8220;trafi&#8221; w nieciągłość (w skok schodka) jest zerowe! Podsumowując, możemy to wszystko zebrać w matematyczną definicję procesu stochastycznego Poissona (lub poissonowskiego procesu urodzin).</p>
<dl class="docutils">
<dt><strong>Definicja</strong></dt>
<dd><p class="first">Procesem Poissona <span class="math">\(N(t)\)</span> nazywamy proces stochastyczny o następujących własnościach:</p>
<ol class="last arabic simple">
<li>Przestrzenią stanów jest zbiór liczb całkowitych nieujemnych, <span class="math">\(X=\{k\}_0^{\infty}\; = \{0, 1, 2, \dots \}\)</span></li>
<li><span class="math">\(N(0) = 0\)</span> (proces startujący z zera)</li>
<li><span class="math">\(N(t_2) - N(t_1)\)</span> jest liczbą punktów w przedziale <span class="math">\((t_1, t_2)\)</span></li>
<li><span class="math">\(N(t)\)</span> ma stacjonarne i niezależne przyrosty na nieprzekrywających się przedziałach o rozkładzie prawdopodobieństwa</li>
</ol>
</dd>
</dl>
<div class="math" id="equation-eqn24">
<span class="eqno">(24)</span>\[  Pr\{N(t_2) - N(t_1) =k\} = e^{-\mu (t_2 - t_1)} \; \frac{[\mu (t_2 - t_1)]^k}{k!}\]</div>
<div class="section" id="wlasnosci-procesu-poissona">
<h3>Własności procesu Poissona<a class="headerlink" href="#wlasnosci-procesu-poissona" title="Stały odnośnik do tego nagłówka">¶</a></h3>
<ol class="arabic simple">
<li>Wartość średnia</li>
</ol>
<blockquote>
<div><div class="math" id="equation-eqn25">
<span class="eqno">(25)</span>\[m(t) = \langle N(t) \rangle = \mu t\]</div>
<p>Z tej relacji mamy interpretację parametru</p>
<div class="math" id="equation-eqn26">
<span class="eqno">(26)</span>\[\mu = \frac{\langle N(t) \rangle}{t}\]</div>
<p>Parametr <span class="math">\(\mu\)</span> to średnia liczba punktów w jednostce czasu lub średnia liczba urodzeń w jednostce czasu. Ten parametr może być
oszacowany z danych statystycznych czy też z danych doświadczalnych.</p>
</div></blockquote>
<ol class="arabic simple" start="2">
<li>Moment statystyczny drugiego rzędu</li>
</ol>
<blockquote>
<div><div class="math" id="equation-eqn27">
<span class="eqno">(27)</span>\[\langle N^2(t) \rangle = \mu^2 t^2 + \mu t\;\]</div>
</div></blockquote>
<ol class="arabic simple" start="3">
<li>Stąd mamy relację dla fluktuacji procesu</li>
</ol>
<blockquote>
<div><div class="math" id="equation-eqn28">
<span class="eqno">(28)</span>\[\sigma^2(t) = \langle N^2(t) \rangle - \langle N(t) \rangle^2 = \mu t \;\]</div>
</div></blockquote>
<ol class="arabic simple" start="4">
<li>Funkcja charakterystyczna <span class="math">\(C(\omega, t)\)</span> procesu Poissona ma postać:</li>
</ol>
<blockquote>
<div><div class="math" id="equation-eqn29">
<span class="eqno">(29)</span>\[C(\omega, t) = \langle \mbox{e}^{i\omega N(t)} \rangle = \sum_{k=0}^{\infty} \mbox{e}^{i\omega k} p_k(t) = \sum_{k=0}^{\infty} \mbox{e}^{i\omega k} \mbox{e}^{-\mu t} \; \frac{(\mu t)^k}{k!} =\]\[= \mbox{e}^{-\mu t} \; \sum_{k=0}^{\infty} \mbox{e}^{i\omega k} \; \frac{(\mu t)^k}{k!} = \mbox{exp}\left[\mu t \left(\mbox{e}^{i\omega} -1\right)\right]\]</div>
</div></blockquote>
<ol class="arabic simple" start="5">
<li>Z p. 3 wynika, że średnio-kwadratowe odchylenie</li>
</ol>
<blockquote>
<div><div class="math" id="equation-eqn30">
<span class="eqno">(30)</span>\[\sigma(t) = \sqrt{\mu t} \;\]</div>
</div></blockquote>
<p>Ważna jest interpretacja tego wyniku: Fluktuacje procesu narastają liniowo w czasie. To oznacza, że im dłuższy jest czas tym odchylenia od wartości średniej mogą być coraz większe. Można przeprowadzić następujące dywagacje:</p>
<p>Badamy proces urodzin i przeprowadzamy szereg symulacji komputerowych tego procesu. Otrzymujemy wiele realizacji procesu urodzin. Z analizy tych realizacji możemy metodami statystyki otrzymać wartość średnią procesu. Oczekujmy (coś to ma wspólnego z wartością oczekiwaną czyli wartością średnią), że wiele realizacji będzie przebiegać w pobliżu wartości średniej. Owszem to prawda, ale jednocześnie pojawiają się realizacje które daleko odbiegają od wartości średniej. Im dłuższy jest ten czas, tym większe odchylenia od wartości średniej mogę zaobserwować. Jest to własność, która w deterministycznym świecie nie występuje (deterministyczny świat nie jest światem rzeczywistym, jest jego idealizacją, bardziej lub mniej adekwatną).</p>
<p>Oczywiście powyższe relacje można podać dla przyrostów procesu Poissona:</p>
<ol class="arabic simple">
<li>Wartość średnia przyrostów procesu Poissona</li>
</ol>
<blockquote>
<div><div class="math" id="equation-eqn31">
<span class="eqno">(31)</span>\[\langle N(t_2) - N(t_1)\rangle = \mu (t_2-t_1)\]</div>
</div></blockquote>
<ol class="arabic simple" start="2">
<li>Moment statystyczny drugiego rzędu dla przyrostów procesu Poissona</li>
</ol>
<blockquote>
<div><div class="math" id="equation-eqn32">
<span class="eqno">(32)</span>\[\langle [N(t_2) - N(t_1)]^2 \rangle = \mu^2 (t_2-t_1)^2 + \mu (t_2-t_1) \;\]</div>
</div></blockquote>
<ol class="arabic simple" start="3">
<li>Funkcja korelacyjna procesu Poissona</li>
</ol>
<blockquote>
<div><div class="math" id="equation-eqn33">
<span class="eqno">(33)</span>\[R(t_2, t_1) = \langle N(t_2) N(t_1)\rangle = \mu^2 \;t_2 \;t_1 + \mu \; \mbox{min}(t_2, t_1) =\]\[= \langle N(t_2)\rangle\langle N(t_1)\rangle+ \mu \; \mbox{min}(t_2, t_1)\]</div>
<p>gdzie funkcja dwóch zmiennych <span class="math">\(\mbox{min}(x, y)\)</span> oznacza wartość mniejszej liczby z dwóch liczb <span class="math">\(x\)</span> i <span class="math">\(y\)</span>:</p>
<div class="math" id="equation-eqn34">
<span class="eqno">(34)</span>\[\begin{split}\mbox{min} (x, y) = \left\{ {{x \; \; \mbox{if}\; \; x &lt; y} \atop {y \; \; \mbox{if} \; \; y&lt;x}}\right\}\end{split}\]</div>
</div></blockquote>
<p>Z powyższych relacji wynika, że <em>proces urodzin jest procesem skorelowanym</em>.</p>
<p>Pokażemy, w jaki sposób można wyznaczyć postać funkcji korelacyjnej. Tą samą metodę stosuje się do obliczenia funkcji korelacyjnej procesu Wienera i procesu Levy&#8217;ego. Dlatego w tych przypadkach czytelnik sam powtórzy wszystkie kroki obliczeń. Rozpatrzymy dwa przypadki pamiętając że <span class="math">\(N(t_0) = N(0) =0\)</span>:</p>
<ol class="arabic simple">
<li>Niech <span class="math">\(t_2 &gt; t_1 &gt; t_0=0\)</span>. Przyrosty <span class="math">\(N(t_2) - N(t_1)\)</span> oraz <span class="math">\(N(t_1) - N(t_0)\)</span> są zmiennymi losowymi niezależnymi dla których</li>
</ol>
<blockquote>
<div><div class="math" id="equation-eqn35">
<span class="eqno">(35)</span>\[\langle[N(t_2) - N(t_1)] [ N(t_1) - N(t_0)] \rangle =\]\[= \langle N(t_2) - N(t_1) \rangle \cdot \langle N(t_1) - N(t_0) \rangle = \mu (t_2 -t_1) \; \mu t_1.\]</div>
<p>Skorzystaliśmy tu z tego, że wartość średnia iloczynu zmiennych losowych niezależnych jest iloczynem wartości średnich zmiennych losowych niezależnych. Z drugiej strony, wymnożymy wyrażenia w nawiasach pamiętając, że <span class="math">\(N(t_0) = N(0) = 0\)</span> (proces Poissona startuje z zera). Wówczas otrzymamy</p>
<div class="math" id="equation-eqn36">
<span class="eqno">(36)</span>\[\langle N(t_2) N(t_1) - N^2(t_1) \rangle = \langle N(t_2) N(t_1) \rangle - \langle N^2(t_1)\rangle =\mu (t_2 -t_1) \; \mu t_1\]</div>
<p>Stąd wynika, że</p>
<div class="math" id="equation-eqn37">
<span class="eqno">(37)</span>\[\langle N(t_2) N(t_1) \rangle = \mu (t_2 -t_1) \; \mu t_1 +\langle N^2(t_1)\rangle =\]\[= \mu (t_2 -t_1) \; \mu t_1 + \mu^2 t_1^2 + \mu t_1\]</div>
<div class="math" id="equation-eqn38">
<span class="eqno">(38)</span>\[\begin{split}\mu^2 t_2 t_1 + \mu t_1 \; \; \; \; \mbox{dla} \; \; \; t_2 &gt; t_1\end{split}\]</div>
</div></blockquote>
<ol class="arabic simple" start="2">
<li>Niech <span class="math">\(t_1 &gt; t_2 &gt; t_0=0\)</span>. Przyrosty <span class="math">\(N(t_1) - N(t_2)\)</span> oraz <span class="math">\(N(t_2) - N(t_0)\)</span> są zmiennymi losowymi niezależnymi. Możemy powtórzyć trzy kroki analogiczne do tych w powyższych trzech równaniach otrzymując</li>
</ol>
<blockquote>
<div><div class="math" id="equation-eqn39">
<span class="eqno">(39)</span>\[\begin{split}\langle N(t_1) N(t_2)\rangle = \mu (t_1 -t_2) \; \mu t_2 + \langle N^2(t_2)\rangle = \mu^2 t_1 t_2 + \mu t_2,\; \mbox{dla} \; t_1 &gt; t_2\end{split}\]</div>
<p>Ponieważ</p>
<div class="math" id="equation-eqn40">
<span class="eqno">(40)</span>\[\langle N(t_2) N(t_1)\rangle = \langle N(t_1) N(t_2)\rangle\]</div>
<p>to z powyższych równań otrzymujemy tezę.</p>
</div></blockquote>
<p>Rozkład prawdopodobieństwa Poissona</p>
<div class="math" id="equation-eqn41">
<span class="eqno">(41)</span>\[ p_k(t) = Pr\{N(t) = k\} = \mbox{e}^{-\mu t} \; \frac{(\mu t)^k}{k!}\]</div>
<p>spełnia następujący układ równań ewolucji (ang. master equations)</p>
<div class="math" id="equation-eqn42">
<span class="eqno">(42)</span>\[\frac{dp_0(t)}{dt} = -\mu p_0(t), \; \; \; p_0(0) = 1\]</div>
<div class="math" id="equation-eqn43">
<span class="eqno">(43)</span>\[\frac{dp_k(t)}{dt} = \mu p_{k-1}(t) -\mu p_k(t), \; \; \; p_k(0) = 0, \; \; \; k=1, 2, 3, \dots\]</div>
<p>Słuszność tego układu równań można sprawdzić bezpośrednim rachunkiem, z jednej strony różniczkując wyrażenie dla <span class="math">\(p_k(t)\)</span>, z drugiej strony wstawiając wrażenia na <span class="math">\(p_k(t)\)</span> oraz <span class="math">\(p_{k-1}(t)\)</span>. Równania te mają też jasną interpretację. W tym celu spojrzymy nieco inaczej na nasz proces. Mówimy, że układ jest w stanie <span class="math">\(k\)</span> jeżeli</p>
<div class="math" id="equation-eqn44">
<span class="eqno">(44)</span>\[N(t) =k\;\]</div>
<p>Stan układu jest określony przez możliwe wartości populacji w danej chwili czasu, <span class="math">\(k=0, 1, 2,....\)</span>.
Zmiana stanu k układu w danej chwili czasu, opisywana przez tempo zmian czyli pochodną <span class="math">\(dp_k(t)/dt\)</span>, może zachodzić z dwóch powodów: albo stan k pojawia się ze stanu (k-1) ponieważ następuje akt narodzin, albo stan k znika i układ przechodzi do stanu k+1 (ponieważ następuje akt narodzin). W wyrażeniu powyższym
wyraz <span class="math">\(\mu p_{k-1}(t)\;\)</span> wchodzi ze znakiem dodatnim ponieważ stan k pojawia się ze stanu k-1; wyraz <span class="math">\(\mu p_{k}(t)\;\)</span> wchodzi ze znakiem ujemnym ponieważ stan k znika i układ przechodzi w stan k+1 (ponieważ ktoś się urodził). Jest to nic innego jak równanie bilansu.</p>
<p>Proces Poissona można uogólnić tak, aby skok nie był tylko w górę o 1. Można modelować skoki w górę i w dół o dowolne wielkości. Mogą to być skoki deterministyczne lub losowe. Oto jedno z możliwych uogólnień:</p>
<div class="math" id="equation-eqn45">
<span class="eqno">(45)</span>\[N(t) = \sum\limits_i z_i \theta (t-t_i), \qquad\]</div>
<p>gdzie <span class="math">\(\theta (x)\)</span> jest funkcją schodkową Heaviside&#8217;a oraz <span class="math">\(\{t_i\}\)</span> jest zbiorem losowych chwil skoków o średniej gęstości <span class="math">\(\mu\)</span>. Amplitudy skoków <span class="math">\(\{z_i\}\)</span> są niezależnymi zmiennymi losowymi o tym samym rozkładzie prawdopodobieństwa <span class="math">\(\rho(z)\)</span> i są niezależne od <span class="math">\(t_i\)</span>. Realizacjami takiego procesu są funkcje schodkowe o skokach w losowych chwilach czasu <span class="math">\(t_i\)</span> i o losowych wielkościach skoku <span class="math">\(z_i\)</span>. Wartość średnia takiego procesu Poissona wynosi</p>
<div class="math" id="equation-eqn46">
<span class="eqno">(46)</span>\[\langle N(t)\rangle = \mu\langle z_i\rangle t\]</div>
<p>gdzie</p>
<div class="math" id="equation-eqn47">
<span class="eqno">(47)</span>\[\langle z_i \rangle = \int_{-\infty}^{\infty} z \rho(z) dz\]</div>
<p>Funkcja korelacyjna tego procesu Poissona ma postać:</p>
<div class="math" id="equation-eqn48">
<span class="eqno">(48)</span>\[R(t_2, t_1) = \langle N(t_2) N(t_1)\rangle = \mu^2 \langle z_i\rangle^2 \;t_2 \;t_1 + \mu \langle z_i\rangle\; \mbox{min}(t_2, t_1) =\]\[= \langle N(t_2)\rangle\langle N(t_1)\rangle+ \mu \;\langle z_i\rangle \mbox{min}(t_2, t_1)\]</div>
<p>Pojedynczą Realizację procesu Poissona można uzyskać poprzez wygenerowanie <tt class="docutils literal"><span class="pre">N</span></tt> niezależnych
punktów losowo rozłożonych na osi czasu na odcinku <span class="math">\([0,T]\)</span>. Ilość punktów generujemy z
rozkładu Poissona a ich położenie na osi czasu zgodnie z rozkładem jednorodnym <span class="math">\(U(0,N)\)</span>.
Najprościej będzie posłużyć się pakietem <tt class="docutils literal"><span class="pre">scipy</span></tt>, aby wygenerować
ilość punktów korzystając z rozkładu Poissona. Punkty czasowe, w których nastąpi skok
uzyskamy wykorzystując podstawową funkcję <tt class="docutils literal"><span class="pre">random()</span></tt>.</p>
<div class='sage'><script type='text/x-sage'>from scipy import stats
import matplotlib.pyplot as plt
T = 15
mu = 1.3
N = stats.poisson.rvs(T*mu)
steps = range(N+1)
points = sorted([random()*T for i in steps])
p = plot_step_function(zip(points,steps),figsize=[8,3])
p.axes_labels([r'$t$',r'$N(t)$'])
p.show()</script></div></div>
</div>
<div class="section" id="proces-levy-ego">
<h2>Proces Levy-ego<a class="headerlink" href="#proces-levy-ego" title="Stały odnośnik do tego nagłówka">¶</a></h2>
<p>Uogólnimy dwa powyższe procesy: Wienera i Poissona, które w potocznym sensie są jednocześnie najbardziej losowe. Są też procesami Markowa. Podkreślamy, że są to podstawowe procesy stochastyczne, ale nie powinno się je nazywać szumem ponieważ nie są to procesy stacjonarne. Są one najbardziej losowe, ponieważ następujące po sobie przyrosty tych procesów są niezależne.</p>
<p>Powyższe dwa procesy są szczególnymi przypadkami procesu który nazywa się procesem Levy&#8217;ego. Wiele innych procesów są albo funkcjami procesu Levy&#8217;ego albo funkcjonałami (trochę ogólniejszymi zależnościami) tego procesu.</p>
<p>Definicja procesu Levy&#8217;ego <span class="math">\(L(t)\)</span> jest relatywnie prosta: jest to rzeczywisty proces stochastyczny, prawostronnie ciągły o skończonych granicach lewostronnych oraz</p>
<ol class="arabic simple">
<li><span class="math">\(L(t)\)</span> startuje z zera, tzn. <span class="math">\(L(0)=0\)</span></li>
<li><span class="math">\(L(t)\)</span> ma niezależne przyrosty na nieprzekrywających się przedziałach, tzn. przyrosty <span class="math">\(L(t_4) -L(t_3)\)</span> oraz <span class="math">\(L(t_2) -L(t_1)\)</span> są niezależnymi zmiennymi losowymi na nieprzekrywających się przedziałach <span class="math">\([t_1, t_2]\)</span> and <span class="math">\([t_3, t_4]\)</span> dla dowolnych chwil czasu takich że <span class="math">\(0 \le t_1 \le t_2 \le t_3 \le t_4\)</span></li>
<li><span class="math">\(L(t)\)</span> ma stacjonarne przyrosty, tzn. rozkład prawdopodobieństwa zmiennych losowych <span class="math">\(L(t_2) -L(t_1)\)</span> zależy od różnicy czasów <span class="math">\(t_2 -t_1\)</span> dla dowolnych <span class="math">\(0 \le t_1 \le t_2\)</span>.</li>
<li><span class="math">\(L(t)\)</span> jest stochastycznie ciągły, tzn. dla dowolnych <span class="math">\(t \ge 0\)</span> oraz <span class="math">\(\epsilon &gt; 0\)</span>:</li>
</ol>
<blockquote>
<div><div class="math" id="equation-eqn49">
<span class="eqno">(49)</span>\[\begin{split}\lim_{s\to t} P(|L(t) -L(s)|&gt;\epsilon)=0\end{split}\]</div>
</div></blockquote>
<p>Własności te są takie same jak dla procesu Wienera i procesu Poissona. Ale istnieją jeszcze inne procesy, które mają te same własności. Dlatego włączenie tych innych procesów do procesu Wienera i Poissona daje w rezultacie proces Levy&#8217;ego.</p>
<p>Z własności (1) i (2) wynika, że funkcja korelacyjna procesu Levy&#8217;ego ma postać (patrz wykłady: Procesy i zjawiska losowe)</p>
<div class="math" id="equation-eqn50">
<span class="eqno">(50)</span>\[\langle L(t) L(s) \rangle = 2D_0 \mbox{min} (t, s) \equiv 2D_0 [t \theta(s-t) + s \theta(t-s)], \qquad\]</div>
<p>gdzie <span class="math">\(D_0 &gt;0\)</span> jest intensywnością (natężeniem) procesu Levy&#8217;ego.</p>
<p>Własności probabilistyczne tego procesu można wyznaczyć np. z jego funkcji charakterystycznej, która zgodnie z twierdzeniem Levy&#8217;ego-Chinczyna ma postać</p>
<div class="math" id="equation-eqn51">
<span class="eqno">(51)</span>\[C(\omega, t) = \langle \mbox{e}^{i\omega L(t)} \rangle = \mbox{e}^{t \psi(\omega)}, \qquad\]</div>
<p>gdzie eksponenta Levy&#8217;ego ma postać</p>
<div class="math" id="equation-eqn52">
<span class="eqno">(52)</span>\[\psi(\omega) = ia_0 \omega -\frac{1}{2} b \omega^2+\int_{-\infty}^{\infty} \left[\mbox{e}^{i\omega y} - 1 - i\omega y I_{(-1,1)}(y) \right] \nu (dy), \qquad\]</div>
<p>Stałe <span class="math">\(a_0\in R, b \ge 0\)</span>. Oznaczenie <span class="math">\(I_A(y)\)</span> jest tzw. indykatorem zbioru <span class="math">\(A\)</span> - jest to funkcja o własności:</p>
<div class="math" id="equation-eqn53">
<span class="eqno">(53)</span>\[ I_A(y) =1 \quad \mbox{gdy} \quad y\in A \quad \mbox{oraz} \quad I_A(y) = 0 \quad \mbox{w pozostałych przypadkach}\]</div>
<p><span class="math">\(\nu(dy)\)</span> jest tzw. miarą Levy&#8217;ego o własności</p>
<div class="math" id="equation-eqn54">
<span class="eqno">(54)</span>\[\begin{split}\nu (R-[-1, 1]) &lt; \infty, \quad \int_{-1}^1 y^2 \nu(dy) &lt; \infty. \qquad\end{split}\]</div>
<p>Dla niewtajemniczonych i nie-ekspertów matematycznych: zamiast tajemniczego zapisu <span class="math">\(\nu(dy)\)</span> można używać zapisu <span class="math">\(\nu(dy) = h(y) dy\)</span> gdzie <span class="math">\(h(y)\)</span> jest nieujemną funkcją. Z powyższego przedstawienia funkcji charakterystycznej wynika, że proces Levy&#8217;ego jest określony przez 3 liczby, tzw. tryplet Levy&#8217;ego-Chinczyna <span class="math">\((a_0, b, \nu)\)</span>, gdzie <span class="math">\(a_0\)</span> charakteryzuje dryf, <span class="math">\(b\)</span> to parametr procesu Wienera oraz <span class="math">\(\nu\)</span> charakteryzuje skoki procesu. Tryplet <span class="math">\((0, b, 0)\)</span> to rozkład Gaussa dla procesu Wienera. Tryplet <span class="math">\((0, 0, \mu \delta(y-1))\)</span> to rozkład Poissona z parametrem <span class="math">\(\mu\)</span> który opisuje proces Poissona o skokach 1 w chwilach o równomiernym rozkładzie. Tzw. złożony proces Poissona to proces o losowych skokach o różnej wielkości z rozkładem prawdopodobieństwa <span class="math">\(\nu\)</span> z <span class="math">\(\nu(R) &lt;\infty\)</span>. Eksponenta Levy&#8217;ego przyjmuje wówczas postać</p>
<div class="math" id="equation-eqn55">
<span class="eqno">(55)</span>\[\psi(\omega) = \mu \int_{-\infty}^{\infty} \left[\mbox{e}^{i\omega y} - 1 \right] \nu (dy). \qquad\]</div>
<p>Jeżeli <span class="math">\(\nu(R) = \infty\)</span> wówczas <span class="math">\(L(t)\)</span> jest skokowym procesem o nieskończonej liczbie małych skoków w dowolnie małym przedziale czasu. W rzeczywistości taki proces nie istnieje, ale jeżeli pojawia się bardzo duża ilość skoków w małych przedziałach czasu, to przybliżenie takie dobrze modeluje układ.</p>
<p>Z twierdzenia Levy&#8217;ego-Ito wynika, że proces Levy&#8217;ego <span class="math">\(L(t)\)</span> składa się z 4 niezależnych procesów elementarnych:</p>
<div class="math" id="equation-eqn56">
<span class="eqno">(56)</span>\[L(t)=L_1(t) +L_2(t) + L_3(t) + L_4(t), \qquad\]</div>
<p>gdzie <span class="math">\(L_1(t)\)</span> to dryf, <span class="math">\(L_2(t)\)</span> to proces Wienera, <span class="math">\(L_3(t)\)</span> to złożony proces Poissona oraz <span class="math">\(L_4(t)\)</span> to czysto skokowy proces zwany martngałem (a pure jump martingale). Mówiąc w prosty sposób, martyngał to taki proces stochastyczny, że warunkowa wartość średnia</p>
<div class="math" id="equation-eqn57">
<span class="eqno">(57)</span>\[\langle L(t_{n+1})|L(t_{1}) L(t_{2})... L(t_{n})\rangle = L(t_{n})\]</div>
<p>Innymi słowy, to taki proces w którym warunkowa wartość średnia procesu w momencie <span class="math">\(t+1\)</span>, gdy znamy jego wartości do jakiegoś wcześniejszego momentu <span class="math">\(t\)</span>, jest równa wartości procesu w momencie <span class="math">\(t\)</span>.</p>
<p>Taka dekompozycja wynika z eksponenty Levy&#8217;ego, która może być przedstawiona w postaci 4 wyrażeń:</p>
<div class="math" id="equation-eqn58">
<span class="eqno">(58)</span>\[\psi(\omega) = \psi_1(\omega) +\psi_2(\omega) +\psi_3(\omega) +\psi_4(\omega), \qquad\]</div>
<p>gdzie</p>
<div class="math" id="equation-eqn59">
<span class="eqno">(59)</span>\[\psi_1(\omega) = i a_0 \omega, \quad \psi_2(\omega) = -\frac{1}{2} b \omega^2, \quad \psi_3(\omega) = \int_{|y| \ge 1} \left[\mbox{e}^{i\omega y} - 1 \right] \nu (dy), \qquad\]</div>
<div class="math" id="equation-eqn60">
<span class="eqno">(60)</span>\[\begin{split}\psi_4(\omega) = \int_{|y| &lt; 1} \left[\mbox{e}^{i\omega y} - 1 - i\omega y \right] \nu (dy).\end{split}\]</div>
<p>Warto podkreślić, że liniowa kombinacja niezależnych procesów Levy&#8217;ego jest także procesem Levy&#8217;ego.</p>
<p>Szczególny, ale bardzo ważnym przypadkiem procesu Levy&#8217;ego jest tzw. <span class="math">\(\alpha\)</span>-stabilny proces <span class="math">\(L_{\alpha}(t)\)</span> 0 indeksie <span class="math">\(\alpha \in (0, 2]\)</span>. To jest przypadek trypletu <span class="math">\((a, 0, \nu)\)</span> z miarą Levy&#8217;ego w postaci</p>
<div class="math" id="equation-eqn61">
<span class="eqno">(61)</span>\[\nu(y) = \left[ c_{1} I_{(0,\infty)}(y) + c_{2} I_{(-\infty,0)}(y) \right] | y|^{-\alpha -1}\ dy, \qquad\]</div>
<p>gdzie <span class="math">\(c_1&gt;0\)</span> i <span class="math">\(c_2&gt;0\)</span>. Eksponenta charakterystyczna jest postaci</p>
<div class="math" id="equation-eqn62">
<span class="eqno">(62)</span>\[\begin{split}\psi(\omega)=\left\{\begin{array}{ll}i a \omega - c | \omega|^\alpha\left (1-i\beta\mbox{sgn}\omega \tan\frac{\pi\alpha}{2} \right), &amp; \mbox{for}\;\;\alpha\neq 1, \\i a \omega -c | \omega|\left (1+i\beta\frac{2}{\pi}\mbox{sgn} \omega \ln|k| \right), &amp; \mbox{for}\;\;\alpha=1, \\\end{array}\right. \qquad\end{split}\]</div>
<p>gdzie</p>
<div class="math" id="equation-eqn63">
<span class="eqno">(63)</span>\[\alpha\in(0, 2], \; \beta =\beta(c_1, c_2) \in [-1, 1], c = c(\alpha, c_1, c_2) \in(0, \infty)\]</div>
<p>oraz <span class="math">\(a = a(a_0, \alpha, c_1, c_2)\)</span>. Przypadek <span class="math">\(c_1=c_2\)</span> implikuje <span class="math">\(\beta=0\)</span> i wówczas proces jest symetryczny.</p>
<p>Tzw. charakterystyczny funkcjonał (pewien szczególny rodzaj odwzorowania, funkcji) symetrycznego <span class="math">\(\alpha\)</span>- stabilnego białego szumu Levy&#8217;ego <span class="math">\(Y_{\alpha}(t)\)</span> (gdy <span class="math">\(a=0, \beta=0\)</span> w równaniu <a href="#equation-eqn62">(62)</a> ) jest w postaci</p>
<div class="math" id="equation-eqn64">
<span class="eqno">(64)</span>\[{\cal C}_{Y_{\alpha}}[f] =\langle {\mbox{exp}}\left[i \int_0^{t} ds\; f(s) Y_{\alpha}(s) \right] \rangle = {\mbox{exp}}\left[- c \int_0^{t} dt\; | (s)|^{\alpha} \right], \qquad\]</div>
<p>Ten zapis ma uzmysłowić, że funkcjonał <span class="math">\({\cal C}\)</span> zależy od historii na przedziale <span class="math">\((0, t)\)</span>. Funkcja <span class="math">\(f\)</span> jest dowolną funkcją. Jeżeli testowa funkcja <span class="math">\(f(t)\)</span> jest stała, <span class="math">\(f(s) =\omega\)</span>, to funkcjonał redukuje się do funkcji charakterystycznej.</p>
<p>Generowanie realizacji procesu Levy&#8217;ego wymaga nieco większego nakładu pracy.
Metoda generowania zmiennych z rozkładu <span class="math">\(\alpha-\)</span> stabilnego opisana jest w
dodatku numerycznym na końcu tego podręcznika. Sama realizacja procesu przebiega
identycznie jak w przypadku procesu Wienera. Jedynymi różnicami są wykładnik
stojący przy prefaktorze zmiennej losowej oraz rozkład którym posługujemy się
do generowania liczb losowych.</p>
<div class='sage'><script type='text/x-sage'>import numpy as np
from scipy import stats
import warnings
warnings.simplefilter('ignore', DeprecationWarning)
# parametry symulacji
h = 0.01 #krok
N = 5000 #ilosc krokow
# parametry SDE
x0 = 0 #wartosc poczatkowa
#Levy - Smirnoff
alpha = 1/2
beta = 1
mu = 0
sigma = 0.1
x = [x0]
for i in xrange(1,N):
  lab = stats.levy_stable.rvs(alpha, beta, loc=mu, scale=sigma)
  x.append(x[i-1] + h**(1/alpha) * lab)
list_plot(x, plotjoined=True, axes_labels=[r'$t$',r'$x(t)$'], figsize=[8,3], frame=1, axes=0)</script></div><p>Korzystając z rozkładu Levy&#8217;ego możemy oczywiście uzyskać zmienne normalne
<span class="math">\(N(0,1)\)</span> kładąc <span class="math">\(\alpha=2, \beta=0, \sigma = 1/\sqrt{2}, \mu=0\)</span>.</p>
<div class='sage'><script type='text/x-sage'>import numpy as np
from scipy import stats
import warnings
warnings.simplefilter('ignore', DeprecationWarning)
# parametry symulacji
h = 0.01 #krok
N = 5000 #ilosc krokow
# parametry SDE
x0 = 0 #wartosc poczatkowa
#N(0,1)
alpha = 2
beta = 0
mu = 0
sigma = 1/sqrt(2.)
x = [x0]
for i in xrange(1,N):
  lab = stats.levy_stable.rvs(alpha, beta, loc=mu, scale=sigma)
  x.append(x[i-1] + h**(1/alpha) * lab)
list_plot(x, plotjoined=True, axes_labels=[r'$t$',r'$x(t)$'], figsize=[8,3], frame=1, axes=0)</script></div></div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <div class="sphinxlocaltoc">
  <h3><a href="../index.html">Spis treści</a></h3>
  <ul>
<li><a class="reference internal" href="#">Podstawowe procesy stochastyczne</a><ul>
<li><a class="reference internal" href="#proces-wienera">Proces Wienera</a></li>
<li><a class="reference internal" href="#proces-poissona">Proces Poissona</a><ul>
<li><a class="reference internal" href="#wlasnosci-procesu-poissona">Własności procesu Poissona</a></li>
</ul>
</li>
<li><a class="reference internal" href="#proces-levy-ego">Proces Levy-ego</a></li>
</ul>
</li>
</ul>

  </div>
  <h4>Poprzedni temat</h4>
  <p class="topless"><a href="chIII011.html"
                        title="poprzedni rozdział">Równania stochastyczne i ich interpretacja</a></p>
  <h4>Następny temat</h4>
  <p class="topless"><a href="chIII030.html"
                        title="następny rozdział">Rachunki w całkach Ito - Stratonowicza</a></p>
  <h3>Ta strona</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/ch3/chIII021.txt"
           rel="nofollow">Pokaż źródło</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Szybkie wyszukiwanie</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Szukaj" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Wprowadź szukany termin lub nazwę modułu, klasy lub funkcji.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
  </div>
  <div class="relbar-bottom">
    
    <div class="related">
      <h3>Nawigacja</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="Indeks ogólny"
             >indeks</a></li>
        <li class="right" >
          <a href="chIII030.html" title="Rachunki w całkach Ito - Stratonowicza"
             >dalej</a> &nbsp; &nbsp;</li>
        <li class="right" >
          <a href="chIII011.html" title="Równania stochastyczne i ich interpretacja"
             >wstecz</a> &nbsp; &nbsp;</li>
  <li><a href="../index.html">Dynamika stochastyczna</a> &raquo;</li>
   
      </ul>
    </div>
  </div>
  
  <div class="footer">
    <a class="logo" href="http://upgow.us.edu.pl/" target="_blank"><img src="_static/upgow.png" alt="UPGOW"/></a><br/>
    &copy; Copyright 2014, Jerzy Łuczka, Łukasz Machura.
    Ostatnia modyfikacja Jan 14, 2014.
    Utworzone przy pomocy <a href="http://sphinx.pocoo.org/">Sphinx</a>'a 1.1.3.
  </div>
  </body>
</html>